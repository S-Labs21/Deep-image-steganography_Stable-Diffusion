{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a06e7b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision.datasets import Flickr8k\n",
    "from diffusers import StableDiffusionPipeline\n",
    "import os\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f882f905",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7416ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = StableDiffusionPipeline.from_pretrained(\"runwayml/stable-diffusion-v1-5\").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((512, 512)),\n",
    "    transforms.ToTensor(),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e72ae4b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc38efdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "FLICKR8K_IMAGES_PATH = \"/content/drive/MyDrive/Flickr8k dataset/Images\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbb989f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Flickr8kDataset(Dataset):\n",
    "    def __init__(self, images_path, transform=None):\n",
    "        super().__init__()\n",
    "        self.images_path = images_path\n",
    "        self.transform = transform\n",
    "        self.image_filenames = os.listdir(images_path)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_filenames)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.image_filenames[idx]\n",
    "        img_path = os.path.join(self.images_path, img_name)\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, img_name  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80f09901",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Flickr8kDataset(FLICKR8K_IMAGES_PATH, transform=transform)\n",
    "dataloader = DataLoader(dataset, batch_size=2, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5beed1e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "cover_image, _ = next(iter(dataloader))\n",
    "secret_image, _ = next(iter(dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc874c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_stegano(cover, secret, alpha=0.1):\n",
    "    \"\"\"Encodes secret into cover image using a weighted blend.\"\"\"\n",
    "    return (1 - alpha) * cover + alpha * secret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04c104f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_stegano(encoded_image, cover_image, alpha=0.1):\n",
    "    \"\"\"Extracts the secret image from the encoded image using inverse blending.\"\"\"\n",
    "    if encoded_image.shape != cover_image.shape:\n",
    "        raise ValueError(\"Encoded and Cover images must have the same shape!\")\n",
    "    secret_recovered = (encoded_image - (1 - alpha) * cover_image) / alpha\n",
    "    secret_recovered = torch.clamp(secret_recovered, 0, 1)\n",
    "    return secret_recovered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "058b5706",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_images(images, titles):\n",
    "    fig, axes = plt.subplots(1, len(images), figsize=(12, 4))\n",
    "    for ax, img, title in zip(axes, images, titles):\n",
    "        if isinstance(img, torch.Tensor):\n",
    "            img = img.permute(1, 2, 0).numpy()\n",
    "        ax.imshow(img)\n",
    "        ax.set_title(title)\n",
    "        ax.axis(\"off\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80f60792",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_image = encode_stegano(cover_image, secret_image, alpha=0.1)\n",
    "decoded_secret_image = decode_stegano(encoded_image, cover_image, alpha=0.1)\n",
    "show_images([cover_image[1], secret_image[1], encoded_image[1], decoded_secret_image[1]],\n",
    "            [\"Cover\", \"Secret\", \"Encoded\", \"Decoded Secret\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cbf60ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.metrics import structural_similarity as ssim\n",
    "from skimage.metrics import mean_squared_error as mse\n",
    "\n",
    "def calculate_metrics(original_image, decoded_image):\n",
    "    \"\"\"Calculates SSIM and MSE between original and decoded images.\"\"\"\n",
    "    # Convert tensors to numpy arrays and scale to 0-255\n",
    "    original_np = (original_image.permute(1, 2, 0).numpy() * 255).astype(np.uint8)\n",
    "    decoded_np = (decoded_image.permute(1, 2, 0).numpy() * 255).astype(np.uint8)\n",
    "\n",
    "    # Ensure images are in grayscale for SSIM calculation if needed, or calculate SSIM per channel\n",
    "    # For simplicity, calculate SSIM on grayscale or average channels\n",
    "    # If images are RGB, SSIM can be calculated per channel and averaged, or convert to grayscale\n",
    "    # For this, we'll convert to grayscale for SSIM.\n",
    "    original_gray = cv2.cvtColor(original_np, cv2.COLOR_RGB2GRAY)\n",
    "    decoded_gray = cv2.cvtColor(decoded_np, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "\n",
    "    ssim_index = ssim(original_gray, decoded_gray)\n",
    "    mean_squared_error = mse(original_np, decoded_np)\n",
    "\n",
    "    return ssim_index, mean_squared_error\n",
    "\n",
    "# `secret_image[1]` is the original secret image and `decoded_secret_image[1]` is the decoded one\n",
    "original_secret = secret_image[1]\n",
    "decoded_secret = decoded_secret_image[1]\n",
    "\n",
    "ssim_score, mse_score = calculate_metrics(original_secret, decoded_secret)\n",
    "\n",
    "print(f\"SSIM: {ssim_score:.4f}\")\n",
    "print(f\"MSE: {mse_score:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
